## **AI Capstone: Final Report Guidelines & Rubric**

**Focus:** A comprehensive, professional document detailing the entire capstone project, from problem definition to final results, deployment, and reflection. This report should demonstrate the integration of knowledge and skills acquired throughout the AI Graduate Certificate program.

**Expected Format & Sections:**

The report should be well-structured, clearly written, and professionally presented. While the exact structure can be adapted slightly, it should generally include the following sections:

1. **Title Page:** Project Title, Student Names, Course Name, Instructor Name, Date.  
2. **Abstract/Executive Summary:** A concise overview (approx. 250-300 words) summarizing the project's objective, approach, key findings, and main conclusions.  
3. **Table of Contents:** List of sections and page numbers.  
4. **List of Figures & Tables:** (If applicable)  
5. **Introduction:**  
   * Background and Motivation: Contextualize the problem. Why is it important?  
   * Problem Statement: Clearly define the specific problem addressed.  
   * Project Objectives: State the specific, measurable goals of the project.  
   * Scope: Reiterate what was in and out of scope.  
   * Report Structure: Briefly outline the remaining sections.  
6. **Literature Review / Background Research:**  
   * Briefly discuss relevant existing work, techniques, or similar projects.  
   * Conduct extensive research investigating literature, reports, whitepapers, blog posts, and any other helpful resource.  
   * How does this project fit into the broader field?  
7. **Methodology:**  
   * Data Acquisition/Simulation: Describe data sources, collection methods, simulation details.  
   * Data Preparation & Feature Engineering: Detail cleaning steps, transformations, feature selection/creation. Justify choices.  
   * Modeling / AI Techniques: Describe the algorithms, models, and techniques used (e.g., specific network architectures, NLP methods, CV approaches, MLOps tools). Provide detailed justifications for choices.  
   * System Architecture & Implementation: Describe the overall system design (diagrams are highly recommended). Detail the tools, libraries, and frameworks used.  
   * Deployment Strategy (If Applicable): Describe the cloud platform, services used, containerization approach, and final deployment configuration.  
   * Evaluation Metrics & Strategy: Define how success was measured (e.g., accuracy, F1-score, precision/recall, latency, qualitative assessment, pipeline success rate).  
8. **Results & Analysis:**  
   * Present the key results clearly (use tables, figures, graphs).  
   * Analyze the results: What do they mean? How well did the models/system perform against the evaluation metrics?  
   * Show outputs/examples from the system (e.g., API responses, dashboard screenshots, generated text, pipeline logs).  
   * Discuss any significant findings or patterns observed.  
9. **Discussion:**  
   * Interpretation of Results: Relate findings back to the project objectives and problem statement. Were the objectives met?  
   * Challenges & Limitations: Discuss significant hurdles encountered and limitations of the final system/approach.  
   * Future Work: Suggest potential improvements or future research directions.  
   * Ethical Considerations (If Applicable): Discuss any ethical implications related to the data, model, or application.  
10. **Conclusion:**  
    * Summarize the project, key achievements, and main takeaways.  
    * Reiterate the significance of the work.  
11. **References:** List all cited sources in a consistent format (e.g., APA, IEEE).  
12. **Appendices (Optional):** Include supplementary material like extensive code snippets (link to repo preferred for full code), detailed data descriptions, user manuals, etc.

**Marking Rubric (Total 100 points)**

| Criterion | Excellent (Highest Point Range) | Good (Mid-High Point Range) | Fair (Mid-Low Point Range) | Poor (Lowest Point Range) | Points |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **1\. Abstract/Executive Summary** | Concise, clear, accurately summarizes all key aspects (objective, approach, findings, conclusion). Engages the reader effectively. | Mostly clear and complete summary, might lack conciseness or miss one minor aspect. | Summary is present but vague, overly long/short, or misses key elements. | Summary is missing, inaccurate, or very poorly written. | **/ 5** |
| **2\. Introduction & Problem Definition** | Compelling background, crystal-clear problem statement, well-defined SMART objectives, precise scope definition. | Good background, clear problem statement and objectives, scope generally clear but could be slightly refined. | Background lacks context, problem/objectives are somewhat vague or poorly defined, scope is unclear. | Background missing/irrelevant, problem/objectives unclear or nonsensical, scope undefined. | **/ 10** |
| **3\. Methodology \- Data & Features** | Thorough, clear description of data acquisition/simulation, prep steps, and feature engineering with strong justification. Easily reproducible. | Good description of data processes, most steps justified. Minor details might be missing for full reproducibility. | Data processes described but lack detail or justification; reproducibility would be difficult. | Data processes are poorly described, missing, or illogical. | **/ 15** |
| **4\. Methodology \- Models & Implementation** | In-depth explanation of models/techniques with strong justification. Clear system architecture (diagrams included). Detailed implementation description. | Clear explanation of models/techniques with adequate justification. Architecture described (diagram may lack some detail). Implementation details mostly clear. | Basic explanation of models/techniques, weak justification. Architecture unclear or missing diagram. Implementation details lack clarity. | Models/techniques poorly explained or inappropriate. Architecture description missing/confusing. Implementation details absent or very unclear. | **/ 20** |
| **5\. Methodology \- Deployment & Evaluation** | Clear, detailed description of deployment strategy (if applicable). Well-defined, appropriate evaluation metrics & strategy fully explained and justified. | Deployment strategy described (if applicable). Evaluation metrics defined and mostly appropriate, strategy explained. | Deployment strategy vague/missing (if applicable). Evaluation metrics poorly defined or inappropriate, strategy unclear. | Deployment strategy absent (if applicable). Evaluation metrics missing or completely inappropriate. | **/ 10** |
| **6\. Results & Analysis** | Results presented exceptionally clearly (effective tables/visuals). Insightful, deep analysis connecting results to objectives. Meaningful interpretation. | Results presented clearly. Good analysis linking results to objectives. Interpretation is sound. | Results presented but may be unclear or poorly visualized. Analysis is superficial or doesn't strongly connect to objectives. Interpretation is basic/flawed. | Results are missing, confusingly presented, or inaccurate. Analysis is absent or nonsensical. | **/ 15** |
| **7\. Discussion** | Thoughtful interpretation, insightful discussion of significant limitations/challenges, realistic and specific future work, relevant ethical considerations. | Good interpretation, discusses limitations/challenges, suggests reasonable future work. Ethical considerations mentioned if applicable. | Basic interpretation, superficial discussion of limitations, vague future work. Limited/no ethical discussion. | Poor/no interpretation, fails to discuss limitations/future work. No ethical considerations. | **/ 10** |
| **8\. Conclusion** | Concise, effective summary of project, key achievements, and significance. Strong final statement. | Good summary of project and achievements. | Basic summary, may miss key takeaways or significance. | Conclusion is missing, repetitive, or does not summarize the project effectively. | **/ 5** |

