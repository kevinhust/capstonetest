## **AI Capstone: Milestone 3 Check-in (Week 9\)**

**Focus:** Demonstrating the core machine learning model(s) or AI components, showing integration into the target application (API, dashboard), and initial steps towards deployment.

**Requirements & Discussion Points:**

Students should be prepared to discuss and demonstrate:

1. **Core Model(s) / AI Component:**  
   * **Demonstrate the trained core model(s).** Discuss the architecture, training process, and key hyperparameters.  
   * Present evaluation results (metrics, plots). How well does the model perform on the defined task? Discuss limitations.  
   * Show code related to model training and evaluation.  
2. **System Integration:**  
   * **Demonstrate the model integrated into the application prototype.**  
     * *API Project:* Show the API endpoint accepting input and returning model predictions/results.  
     * *Dashboard Project:* Show the dashboard using model outputs to generate visualizations or insights.  
     * *Pipeline Project:* Show the relevant pipeline step executing the model training/evaluation.  
   * Discuss challenges faced during integration.  
3. **Initial Deployment Steps (If Applicable):**  
   * Show the Dockerfile created for the application/service.  
   * Discuss the chosen cloud platform and deployment strategy (e.g., which services: Cloud Run, SageMaker, App Service, etc.).  
   * Describe any initial setup done on the cloud platform (even if deployment isn't fully working yet).  
4. **Progress & Planning:**  
   * Review progress against the plan set in Milestone 2\.  
   * Detailed task breakdown for the *next 3 weeks* (leading to Milestone 4), focusing on end-to-end functionality, deployment, testing, and documentation.  
   * Identify key remaining challenges for completing the project.

**Marking Scheme (Informal Discussion-Based Assessment \- Total 25 points)**

* **1\. Core Model Development & Evaluation (6 points):**  
  * (0-2) Model is non-functional, poorly chosen, or evaluation is missing/flawed.  
  * (3-4) Model works but performance is low or evaluation is basic; training process unclear.  
  * (5-6) Appropriate model developed, training process clear, solid evaluation presented with relevant metrics and discussion of limitations.  
* **2\. System Integration Demonstration (6 points):**  
  * (0-2) Integration attempt failed or not demonstrated.  
  * (3-4) Basic integration shown but buggy or limited; demonstration struggles.  
  * (5-6) Clear demonstration of the model integrated and functioning within the application context (API response, dashboard visualization, pipeline step execution).  
* **3\. Deployment Preparation (Dockerfile & Plan) (5 points):**  
  * (0-1) No Dockerfile or deployment plan discussed.  
  * (2-3) Basic Dockerfile exists OR deployment plan is vague; minimal cloud setup.  
  * (4-5) Functional Dockerfile demonstrated; clear deployment strategy and choice of cloud services discussed; initial cloud setup may be shown.  
* **4\. Progress & Forward Planning (4 points):**  
  * (0-1) Significant delays; plan for completion is unclear or unrealistic.  
  * (2) Reasonable progress; basic plan for next 3 weeks outlined.  
  * (3-4) Good progress aligned with previous plan; detailed, achievable plan for Milestone 4 presented, including testing and documentation.  
* **5\. Problem Solving & Technical Depth (4 points):**  
  * (0-1) Unable to discuss technical challenges or solutions coherently.  
  * (2) Can discuss technical aspects at a surface level; some problem-solving evident.  
  * (3-4) Demonstrates clear understanding of technical details, discusses challenges and solutions effectively; shows technical depth.

**Feedback:** Verbal feedback will concentrate on the model's effectiveness, the success of the integration, the feasibility of the deployment plan, and the critical path to project completion.